{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aadc8aac",
   "metadata": {},
   "source": [
    "# About the notebook\n",
    "This script computes logistic regresson models based on the features generated as part of the thesis. Different adjustments of the models are tested (e.g. scaled data, Principal Component Analysis for dimensionality reduction, adjusting the hyperparameter, hyperparameter optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1df1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve,auc,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d60e26",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a768cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "cancer_type = \"breast_cancer\"\n",
    "GC = \"corrected\"\n",
    "score = \"MIDPOINT\"\n",
    "amplitude = \"FFT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c969cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancer features\n",
    "file = \"/data/gpfs-1/groups/ag_kircher/cfDNA-analysis/lea/cfDNA_classification_analyses/features/DELFI_\"+cancer_type+\"_\"+GC+\"_\"+score+\"_\"+amplitude+\"_features.csv\"\n",
    "c_features = pd.read_csv(file, sep=\"\\t\", index_col=0)\n",
    "\n",
    "file = \"/data/gpfs-1/groups/ag_kircher/cfDNA-analysis/lea/cfDNA_classification_analyses/features/DELFI_\"+cancer_type+\"_metadata.tsv\"\n",
    "c_meta = pd.read_csv(file, sep='\\t', index_col='sample_name')\n",
    "\n",
    "c_features = c_features.reset_index(drop=False)\n",
    "c_features[['sample','p','score']] = c_features['index'].str.split('_',2, expand=True)\n",
    "c_features = c_features.set_index('sample')\n",
    "cancer = pd.concat([c_features, c_meta], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757b1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# healthy features\n",
    "file = \"/data/gpfs-1/groups/ag_kircher/cfDNA-analysis/lea/cfDNA_classification_analyses/features/DELFI_healthy_\"+GC+\"_\"+score+\"_\"+amplitude+\"_features.csv\"\n",
    "h_features = pd.read_csv(file, sep=\"\\t\", index_col=0)\n",
    "\n",
    "file = \"/data/gpfs-1/groups/ag_kircher/cfDNA-analysis/lea/cfDNA_classification_analyses/features/DELFI_healthy_metadata.tsv\"\n",
    "h_meta = pd.read_csv(file, sep='\\t', index_col='sample_name')\n",
    "\n",
    "h_features = h_features.reset_index(drop=False)\n",
    "h_features[['sample','p','score']] = h_features['index'].str.split('_',2, expand=True)\n",
    "h_features = h_features.set_index('sample')\n",
    "healthy = pd.concat([h_features, h_meta], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556c2dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>central_coverage_NFKB2</th>\n",
       "      <th>mean_coverage_NFKB2</th>\n",
       "      <th>amplitude190_NFKB2</th>\n",
       "      <th>nucleosome_spacing_fft_NFKB2</th>\n",
       "      <th>central_coverage_TP73</th>\n",
       "      <th>mean_coverage_TP73</th>\n",
       "      <th>amplitude190_TP73</th>\n",
       "      <th>nucleosome_spacing_fft_TP73</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Age</th>\n",
       "      <th>Status</th>\n",
       "      <th>% GC</th>\n",
       "      <th>Length</th>\n",
       "      <th>Median</th>\n",
       "      <th>≥ 1X</th>\n",
       "      <th>≥ 5X</th>\n",
       "      <th>fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EGAF00002727253</th>\n",
       "      <td>EGAF00002727253_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921859</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>5.964870</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.993629</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>15.140059</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>I</td>\n",
       "      <td>54.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>140 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.06429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727240</th>\n",
       "      <td>EGAF00002727240_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966934</td>\n",
       "      <td>1.000200</td>\n",
       "      <td>19.353707</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.033113</td>\n",
       "      <td>1.000039</td>\n",
       "      <td>9.433198</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>61.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>42%</td>\n",
       "      <td>143 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>3.0%</td>\n",
       "      <td>0.36440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727280</th>\n",
       "      <td>EGAF00002727280_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.161236</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>11.505221</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1.115174</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>17.278634</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>37.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>42%</td>\n",
       "      <td>134 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.09767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727290</th>\n",
       "      <td>EGAF00002727290_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.027811</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>20.178665</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.038958</td>\n",
       "      <td>1.000246</td>\n",
       "      <td>3.898227</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>48.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>139 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>89.0%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>0.06922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727254</th>\n",
       "      <td>EGAF00002727254_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.118326</td>\n",
       "      <td>1.000246</td>\n",
       "      <td>10.611337</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1.166457</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>1.834101</td>\n",
       "      <td>213.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>47.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>134 bp</td>\n",
       "      <td>1.0X</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.11470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1523 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      index  phenotype  \\\n",
       "EGAF00002727253  EGAF00002727253_c_MIDPOINT        1.0   \n",
       "EGAF00002727240  EGAF00002727240_c_MIDPOINT        1.0   \n",
       "EGAF00002727280  EGAF00002727280_c_MIDPOINT        1.0   \n",
       "EGAF00002727290  EGAF00002727290_c_MIDPOINT        1.0   \n",
       "EGAF00002727254  EGAF00002727254_c_MIDPOINT        1.0   \n",
       "\n",
       "                 central_coverage_NFKB2  mean_coverage_NFKB2  \\\n",
       "EGAF00002727253                0.921859             0.999899   \n",
       "EGAF00002727240                0.966934             1.000200   \n",
       "EGAF00002727280                1.161236             0.999987   \n",
       "EGAF00002727290                1.027811             0.999776   \n",
       "EGAF00002727254                1.118326             1.000246   \n",
       "\n",
       "                 amplitude190_NFKB2  nucleosome_spacing_fft_NFKB2  \\\n",
       "EGAF00002727253            5.964870                         148.0   \n",
       "EGAF00002727240           19.353707                         192.0   \n",
       "EGAF00002727280           11.505221                         213.0   \n",
       "EGAF00002727290           20.178665                         192.0   \n",
       "EGAF00002727254           10.611337                         213.0   \n",
       "\n",
       "                 central_coverage_TP73  mean_coverage_TP73  amplitude190_TP73  \\\n",
       "EGAF00002727253               0.993629            0.999585          15.140059   \n",
       "EGAF00002727240               1.033113            1.000039           9.433198   \n",
       "EGAF00002727280               1.115174            0.999805          17.278634   \n",
       "EGAF00002727290               1.038958            1.000246           3.898227   \n",
       "EGAF00002727254               1.166457            0.999947           1.834101   \n",
       "\n",
       "                 nucleosome_spacing_fft_TP73  ...  Gender  Stage   Age  \\\n",
       "EGAF00002727253                        192.0  ...       F      I  54.0   \n",
       "EGAF00002727240                        240.0  ...       F     II  61.0   \n",
       "EGAF00002727280                        192.0  ...       F     II  37.0   \n",
       "EGAF00002727290                        160.0  ...       F     II  48.0   \n",
       "EGAF00002727254                        213.0  ...       F     II  47.0   \n",
       "\n",
       "                        Status  % GC  Length  Median   ≥ 1X  ≥ 5X  fraction  \n",
       "EGAF00002727253  breast_cancer   41%  140 bp    2.0X  88.0%  1.0%   0.06429  \n",
       "EGAF00002727240  breast_cancer   42%  143 bp    2.0X  88.0%  3.0%   0.36440  \n",
       "EGAF00002727280  breast_cancer   42%  134 bp    2.0X  86.0%  1.0%   0.09767  \n",
       "EGAF00002727290  breast_cancer   41%  139 bp    2.0X  89.0%  2.0%   0.06922  \n",
       "EGAF00002727254  breast_cancer   41%  134 bp    1.0X  86.0%  1.0%   0.11470  \n",
       "\n",
       "[5 rows x 1523 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat breast cancer and healthy\n",
    "data = pd.concat([cancer, healthy], axis=0) #pd.concat([data1, data2], axis=0)\n",
    "\n",
    "# nucleosome_spacing_fft\n",
    "features = data.columns[(data.columns.str.startswith('central_cov')) | (data.columns.str.startswith('mean_cov')) | (data.columns.str.startswith('amplitude'))]\n",
    "features_phenotype = data.columns[(data.columns.str.startswith('phenotype')) | (data.columns.str.startswith('central_cov')) | (data.columns.str.startswith('mean_cov')) | (data.columns.str.startswith('amplitude'))]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53226e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>central_coverage_NFKB2</th>\n",
       "      <th>mean_coverage_NFKB2</th>\n",
       "      <th>amplitude190_NFKB2</th>\n",
       "      <th>nucleosome_spacing_fft_NFKB2</th>\n",
       "      <th>central_coverage_TP73</th>\n",
       "      <th>mean_coverage_TP73</th>\n",
       "      <th>amplitude190_TP73</th>\n",
       "      <th>nucleosome_spacing_fft_TP73</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Age</th>\n",
       "      <th>Status</th>\n",
       "      <th>% GC</th>\n",
       "      <th>Length</th>\n",
       "      <th>Median</th>\n",
       "      <th>≥ 1X</th>\n",
       "      <th>≥ 5X</th>\n",
       "      <th>fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EGAF00002727253</th>\n",
       "      <td>EGAF00002727253_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.587964</td>\n",
       "      <td>-0.402804</td>\n",
       "      <td>-1.431977</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-1.235524</td>\n",
       "      <td>-2.211313</td>\n",
       "      <td>0.879156</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>I</td>\n",
       "      <td>54.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>140 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.06429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727240</th>\n",
       "      <td>EGAF00002727240_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.575681</td>\n",
       "      <td>1.081786</td>\n",
       "      <td>0.380465</td>\n",
       "      <td>192.0</td>\n",
       "      <td>-0.233665</td>\n",
       "      <td>0.148223</td>\n",
       "      <td>-0.184884</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>61.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>42%</td>\n",
       "      <td>143 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>3.0%</td>\n",
       "      <td>0.36440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727280</th>\n",
       "      <td>EGAF00002727280_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.787805</td>\n",
       "      <td>0.031149</td>\n",
       "      <td>-0.681981</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1.848499</td>\n",
       "      <td>-1.066968</td>\n",
       "      <td>1.277891</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>37.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>42%</td>\n",
       "      <td>134 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.09767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727290</th>\n",
       "      <td>EGAF00002727290_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791448</td>\n",
       "      <td>-1.014266</td>\n",
       "      <td>0.492140</td>\n",
       "      <td>192.0</td>\n",
       "      <td>-0.085350</td>\n",
       "      <td>1.227604</td>\n",
       "      <td>-1.216876</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>48.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>139 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>89.0%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>0.06922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727254</th>\n",
       "      <td>EGAF00002727254_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.824170</td>\n",
       "      <td>1.308605</td>\n",
       "      <td>-0.802986</td>\n",
       "      <td>213.0</td>\n",
       "      <td>3.149750</td>\n",
       "      <td>-0.327229</td>\n",
       "      <td>-1.601730</td>\n",
       "      <td>213.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>47.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>134 bp</td>\n",
       "      <td>1.0X</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.11470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1523 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      index  phenotype  \\\n",
       "EGAF00002727253  EGAF00002727253_c_MIDPOINT        1.0   \n",
       "EGAF00002727240  EGAF00002727240_c_MIDPOINT        1.0   \n",
       "EGAF00002727280  EGAF00002727280_c_MIDPOINT        1.0   \n",
       "EGAF00002727290  EGAF00002727290_c_MIDPOINT        1.0   \n",
       "EGAF00002727254  EGAF00002727254_c_MIDPOINT        1.0   \n",
       "\n",
       "                 central_coverage_NFKB2  mean_coverage_NFKB2  \\\n",
       "EGAF00002727253               -1.587964            -0.402804   \n",
       "EGAF00002727240               -0.575681             1.081786   \n",
       "EGAF00002727280                3.787805             0.031149   \n",
       "EGAF00002727290                0.791448            -1.014266   \n",
       "EGAF00002727254                2.824170             1.308605   \n",
       "\n",
       "                 amplitude190_NFKB2  nucleosome_spacing_fft_NFKB2  \\\n",
       "EGAF00002727253           -1.431977                         148.0   \n",
       "EGAF00002727240            0.380465                         192.0   \n",
       "EGAF00002727280           -0.681981                         213.0   \n",
       "EGAF00002727290            0.492140                         192.0   \n",
       "EGAF00002727254           -0.802986                         213.0   \n",
       "\n",
       "                 central_coverage_TP73  mean_coverage_TP73  amplitude190_TP73  \\\n",
       "EGAF00002727253              -1.235524           -2.211313           0.879156   \n",
       "EGAF00002727240              -0.233665            0.148223          -0.184884   \n",
       "EGAF00002727280               1.848499           -1.066968           1.277891   \n",
       "EGAF00002727290              -0.085350            1.227604          -1.216876   \n",
       "EGAF00002727254               3.149750           -0.327229          -1.601730   \n",
       "\n",
       "                 nucleosome_spacing_fft_TP73  ...  Gender  Stage   Age  \\\n",
       "EGAF00002727253                        192.0  ...       F      I  54.0   \n",
       "EGAF00002727240                        240.0  ...       F     II  61.0   \n",
       "EGAF00002727280                        192.0  ...       F     II  37.0   \n",
       "EGAF00002727290                        160.0  ...       F     II  48.0   \n",
       "EGAF00002727254                        213.0  ...       F     II  47.0   \n",
       "\n",
       "                        Status  % GC  Length  Median   ≥ 1X  ≥ 5X  fraction  \n",
       "EGAF00002727253  breast_cancer   41%  140 bp    2.0X  88.0%  1.0%   0.06429  \n",
       "EGAF00002727240  breast_cancer   42%  143 bp    2.0X  88.0%  3.0%   0.36440  \n",
       "EGAF00002727280  breast_cancer   42%  134 bp    2.0X  86.0%  1.0%   0.09767  \n",
       "EGAF00002727290  breast_cancer   41%  139 bp    2.0X  89.0%  2.0%   0.06922  \n",
       "EGAF00002727254  breast_cancer   41%  134 bp    1.0X  86.0%  1.0%   0.11470  \n",
       "\n",
       "[5 rows x 1523 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale data\n",
    "scaled_data = pd.concat([cancer, healthy], axis=0) \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(scaled_data[features])\n",
    "scaled_data[features] = scaler.transform(scaled_data[features])\n",
    "scaled_data[features].mean()\n",
    "\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9a76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into a training (75%) and testing set (25%)\n",
    "train,test = train_test_split(data, test_size = 0.25, random_state = 100) #, random_state = 42\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train.loc[:,\"phenotype\"]\n",
    "X_test = test[features]\n",
    "y_test = test.loc[:,\"phenotype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01bbb9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split scaled data into a training (75%) and testing set (25%)\n",
    "train_scaled,test_scaled = train_test_split(scaled_data, test_size = 0.25, random_state = 42)\n",
    "\n",
    "X_train_scaled = train_scaled[features]\n",
    "y_train_scaled = train_scaled.loc[:,\"phenotype\"]\n",
    "X_test_scaled = test_scaled[features]\n",
    "y_test_scaled = test_scaled.loc[:,\"phenotype\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd4e7b",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0592e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_logReg(data, PCA_flag, adjustment_flag, iterations):\n",
    "    fraction_variance = .8\n",
    "    probabilities = pd.DataFrame(index=data.index)\n",
    "    coefs = pd.DataFrame(index=features)\n",
    "    train_indexes = []\n",
    "\n",
    "    # Loop for each iteration\n",
    "    for i in range(iterations):\n",
    "\n",
    "        train,test = train_test_split(data, test_size = 0.25, random_state = i+100)\n",
    "        X_train = train[features]\n",
    "        y_train = train.loc[:,\"phenotype\"]\n",
    "        X_test = test[features]\n",
    "        y_test = test.loc[:,\"phenotype\"]\n",
    "    \n",
    "        if PCA_flag == True:\n",
    "            #perform PCA on the training set\n",
    "            n_components = min(len(features), len(X_train))\n",
    "            pca = PCA(n_components=n_components, svd_solver='randomized', random_state = 100)\n",
    "            PCs = pca.fit_transform(X_train[features])\n",
    "            principal_components = pd.DataFrame(data = PCs, columns = ['PC_'+str(m) for m in np.arange(n_components)], index = X_train.index)\n",
    "\n",
    "            #find the principle components that make up 80% of the varience\n",
    "            for j in range(len(pca.explained_variance_ratio_)):\n",
    "                current_sum = pca.explained_variance_ratio_[:j].sum()\n",
    "                if current_sum>=fraction_variance:\n",
    "                    break\n",
    "            pca_features = ['PC_'+str(m) for m in np.arange(0,j)]\n",
    "\n",
    "            #apply to the test data\n",
    "            test_PCs = pca.transform(X_test[features])\n",
    "            test_principal_components = pd.DataFrame(data = test_PCs , columns = ['PC_'+str(m) for m in np.arange(n_components)], index = X_test.index)\n",
    "\n",
    "            X_train = principal_components[pca_features]\n",
    "            X_test = test_principal_components[pca_features]\n",
    "\n",
    "        if adjustment_flag == True:\n",
    "            model = LogisticRegression(class_weight='balanced', max_iter=500, solver = 'liblinear')\n",
    "        else:\n",
    "            model = LogisticRegression(class_weight='balanced', max_iter=500)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        #predict the test data\n",
    "        pred = model.predict(X_test)\n",
    "        prob = model.predict_proba(X_test)\n",
    "\n",
    "        #save results\n",
    "        probabilities[i] = pd.Series(prob[:,1], index = X_test.index)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        train_indexes.append(list(X_train.index))\n",
    "\n",
    "        if i%20==0:\n",
    "            #prevent dfs from becoming too fragmented\n",
    "            probabilities = probabilities.copy()\n",
    "            coefs = coefs.copy()\n",
    "\n",
    "    probabilities = probabilities.merge(data[['phenotype']], left_index=True, right_index=True)\n",
    "    AUCs = pd.DataFrame()\n",
    "    probabilities = probabilities.merge(data[['fraction','Status','Stage']], left_index=True, right_index=True)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        current_dict = {}\n",
    "        current = probabilities[~(probabilities[i].isnull())][['phenotype','fraction','Status','Stage',i]].copy()\n",
    "\n",
    "        #overall accuracy and AUC\n",
    "        group = 'overall'\n",
    "        fpr,tpr,_ = roc_curve(current['phenotype'],current[i])\n",
    "        AUC = auc(fpr,tpr)\n",
    "        current_dict[group] = AUC\n",
    "        del(AUC,group,fpr,tpr)\n",
    "\n",
    "        #separate out the healthy samples to be used in every AUC\n",
    "        healthy_df = current[current['phenotype']==0]\n",
    "        cancer_df = current[current['phenotype']==1]\n",
    "        del(current)\n",
    "\n",
    "        for group,df in cancer_df.groupby('Status'):\n",
    "            if group == 'Duodenal_Cancer':\n",
    "                continue\n",
    "\n",
    "            df2 = df.append(healthy_df, ignore_index=True)\n",
    "            fpr,tpr,_ = roc_curve(df2['phenotype'],df2[i])\n",
    "            AUC = auc(fpr,tpr)\n",
    "            current_dict[group] = AUC\n",
    "            del(AUC,group,fpr,tpr)\n",
    "\n",
    "        AUCs = AUCs.append(pd.Series(current_dict), ignore_index=True)\n",
    "\n",
    "    CIs = pd.DataFrame([AUCs.median(), AUCs.quantile(.025), AUCs.quantile(.975)]).T\n",
    "    CIs = CIs.rename(columns = {'Unnamed 0':'median'}) \n",
    "    return(acc,CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94511fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization_logReg(data, PCA_flag, iterations):\n",
    "    fraction_variance = .8\n",
    "    probabilities = pd.DataFrame(index=data.index)\n",
    "    coefs = pd.DataFrame(index=features)\n",
    "    train_indexes = []\n",
    "\n",
    "    # Loop for each iteration\n",
    "    for i in range(iterations):\n",
    "\n",
    "        train,test = train_test_split(data, test_size = 0.25, random_state = i+100)\n",
    "        X_train = train[features]\n",
    "        y_train = train.loc[:,\"phenotype\"]\n",
    "        X_test = test[features]\n",
    "        y_test = test.loc[:,\"phenotype\"]\n",
    "    \n",
    "        if PCA_flag == True:\n",
    "            #perform PCA on the training set\n",
    "            n_components = min(len(features), len(X_train))\n",
    "            pca = PCA(n_components=n_components, svd_solver='randomized', random_state = 100)\n",
    "            PCs = pca.fit_transform(X_train[features])\n",
    "            principal_components = pd.DataFrame(data = PCs, columns = ['PC_'+str(m) for m in np.arange(n_components)], index = X_train.index)\n",
    "\n",
    "            #find the principle components that make up 80% of the varience\n",
    "            for j in range(len(pca.explained_variance_ratio_)):\n",
    "                current_sum = pca.explained_variance_ratio_[:j].sum()\n",
    "                if current_sum>=fraction_variance:\n",
    "                    break\n",
    "            pca_features = ['PC_'+str(m) for m in np.arange(0,j)]\n",
    "\n",
    "            #apply to the test data\n",
    "            test_PCs = pca.transform(X_test[features])\n",
    "            test_principal_components = pd.DataFrame(data = test_PCs , columns = ['PC_'+str(m) for m in np.arange(n_components)], index = X_test.index)\n",
    "\n",
    "            X_train = principal_components[pca_features]\n",
    "            X_test = test_principal_components[pca_features]\n",
    "        \n",
    "        if i == 0:\n",
    "            hyperparameters = {'C': [0.0001, 0.001,0.01,0.1,1,10,100,1000]}\n",
    "            cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = i+100) \n",
    "            model = LogisticRegression(class_weight='balanced', max_iter=500, solver = 'liblinear')\n",
    "            search = GridSearchCV(estimator=model, param_grid=hyperparameters, cv=cv, n_jobs = 1)\n",
    "            search.fit(X_train, y_train)\n",
    "            best_C = search.best_params_['C']\n",
    "\n",
    "        ##train a new model on the full training dataset\n",
    "        model = LogisticRegression(class_weight='balanced', max_iter=500, C=best_C, solver = 'liblinear')\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        #predict the test data\n",
    "        pred = model.predict(X_test)\n",
    "        prob = model.predict_proba(X_test)\n",
    "\n",
    "        #save results\n",
    "        probabilities[i] = pd.Series(prob[:,1], index = X_test.index)\n",
    "        acc = accuracy_score(y_test, pred)\n",
    "        train_indexes.append(list(X_train.index))\n",
    "\n",
    "        if i%20==0:\n",
    "            #prevent dfs from becoming too fragmented\n",
    "            probabilities = probabilities.copy()\n",
    "            coefs = coefs.copy()\n",
    "\n",
    "    probabilities = probabilities.merge(data[['phenotype']], left_index=True, right_index=True)\n",
    "    AUCs = pd.DataFrame()\n",
    "    probabilities = probabilities.merge(data[['fraction','Status','Stage']], left_index=True, right_index=True)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        current_dict = {}\n",
    "        current = probabilities[~(probabilities[i].isnull())][['phenotype','fraction','Status','Stage',i]].copy()\n",
    "\n",
    "        #overall accuracy and AUC\n",
    "        group = 'overall'\n",
    "        fpr,tpr,_ = roc_curve(current['phenotype'],current[i])\n",
    "        AUC = auc(fpr,tpr)\n",
    "        current_dict[group] = AUC\n",
    "        del(AUC,group,fpr,tpr)\n",
    "\n",
    "        #separate out the healthy samples to be used in every AUC\n",
    "        healthy_df = current[current['phenotype']==0]\n",
    "        cancer_df = current[current['phenotype']==1]\n",
    "        del(current)\n",
    "\n",
    "        for group,df in cancer_df.groupby('Status'):\n",
    "            if group == 'Duodenal_Cancer':\n",
    "                continue\n",
    "\n",
    "            df2 = df.append(healthy_df, ignore_index=True)\n",
    "            fpr,tpr,_ = roc_curve(df2['phenotype'],df2[i])\n",
    "            AUC = auc(fpr,tpr)\n",
    "            current_dict[group] = AUC\n",
    "            del(AUC,group,fpr,tpr)\n",
    "\n",
    "        AUCs = AUCs.append(pd.Series(current_dict), ignore_index=True)\n",
    "\n",
    "    CIs = pd.DataFrame([AUCs.median(), AUCs.quantile(.025), AUCs.quantile(.975)]).T\n",
    "    CIs = CIs.rename(columns = {'Unnamed 0':'median'}) \n",
    "    return(acc,CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8a768",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "First train a logistic regression model with all features on default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e04b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5185185185185185\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.611111  0.611111  0.611111\n",
      "overall        0.611111  0.611111  0.611111\n"
     ]
    }
   ],
   "source": [
    "# default model \n",
    "acc,CIs = calculate_logReg(data, False, False, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d553f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.758242  0.593344  0.905582\n",
      "overall        0.758242  0.593344  0.905582\n"
     ]
    }
   ],
   "source": [
    "# default model over 1,000 iterations\n",
    "acc,CIs = calculate_logReg(data, False, False, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e11b706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5185185185185185\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.438889  0.438889  0.438889\n",
      "overall        0.438889  0.438889  0.438889\n"
     ]
    }
   ],
   "source": [
    "# default model using Principal Component Analysis to reduce dimensionality\n",
    "acc,CIs = calculate_logReg(data, True, False, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "316ae132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296296296296297\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.681319  0.499863  0.840997\n",
      "overall        0.681319  0.499863  0.840997\n"
     ]
    }
   ],
   "source": [
    "# default model using Principal Component Analysis to reduce dimensionality over 1,000 iterations\n",
    "acc,CIs = calculate_logReg(data, True, False, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc72875",
   "metadata": {},
   "source": [
    "Rerun the models using scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da59040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296296296296297\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.711111  0.711111  0.711111\n",
      "overall        0.711111  0.711111  0.711111\n"
     ]
    }
   ],
   "source": [
    "# default model with scaled data\n",
    "acc,CIs = calculate_logReg(scaled_data, False, False, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "379f0221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296296296296297\n",
      "                 median  0.025     0.975\n",
      "breast_cancer  0.852273    0.7  0.966667\n",
      "overall        0.852273    0.7  0.966667\n"
     ]
    }
   ],
   "source": [
    "# default model over 1,000 iterations with scaled data\n",
    "acc,CIs = calculate_logReg(scaled_data, False, False, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdf5e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296296296296297\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.616667  0.616667  0.616667\n",
      "overall        0.616667  0.616667  0.616667\n"
     ]
    }
   ],
   "source": [
    "# default model using Principal Component Analysis to reduce dimensionality with scaled data\n",
    "acc,CIs = calculate_logReg(scaled_data, True, False, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0ee99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296296296296297\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.811438  0.633267  0.939651\n",
      "overall        0.811438  0.633267  0.939651\n"
     ]
    }
   ],
   "source": [
    "# default model using Principal Component Analysis to reduce dimensionality over 1,000 iterations with scaled data\n",
    "acc,CIs = calculate_logReg(scaled_data, True, False, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285ac188",
   "metadata": {},
   "source": [
    "Now use a gradient boosting model with adjusted hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "130e3e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5185185185185185\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.611111  0.611111  0.611111\n",
      "overall        0.611111  0.611111  0.611111\n"
     ]
    }
   ],
   "source": [
    "# adjusted model \n",
    "acc,CIs = calculate_logReg(data, False, True, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad8c1ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.758533  0.590842  0.905556\n",
      "overall        0.758533  0.590842  0.905556\n"
     ]
    }
   ],
   "source": [
    "# adjusted model over 1,000 iterations\n",
    "acc,CIs = calculate_logReg(data, False, True, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d682aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5185185185185185\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.427778  0.427778  0.427778\n",
      "overall        0.427778  0.427778  0.427778\n"
     ]
    }
   ],
   "source": [
    "# adjusted model using Principal Component Analysis to reduce dimensionality\n",
    "acc,CIs = calculate_logReg(data, True, True, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3c5b917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296296296296297\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.681319  0.494504  0.841258\n",
      "overall        0.681319  0.494504  0.841258\n"
     ]
    }
   ],
   "source": [
    "# adjusted model using Principal Component Analysis to reduce dimensionality over 1,000 iterations\n",
    "acc,CIs = calculate_logReg(data, True, True, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a85c88",
   "metadata": {},
   "source": [
    "And use the adjusted model with scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5641f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7037037037037037\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.716667  0.716667  0.716667\n",
      "overall        0.716667  0.716667  0.716667\n"
     ]
    }
   ],
   "source": [
    "# adjusted model with scaled data\n",
    "acc,CIs = calculate_logReg(scaled_data, False, True, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a62ef82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5925925925925926\n",
      "               median     0.025     0.975\n",
      "breast_cancer    0.85  0.694436  0.966667\n",
      "overall          0.85  0.694436  0.966667\n"
     ]
    }
   ],
   "source": [
    "# adjusted model over 1,000 iterations with scaled data\n",
    "acc,CIs = calculate_logReg(scaled_data, False, True, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1bcfedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5925925925925926\n",
      "               median  0.025  0.975\n",
      "breast_cancer     0.6    0.6    0.6\n",
      "overall           0.6    0.6    0.6\n"
     ]
    }
   ],
   "source": [
    "# adjusted model using Principal Component Analysis to reduce dimensionality with scaled data\n",
    "acc,CIs = calculate_logReg(scaled_data, True, True, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cd47e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "                 median     0.025   0.975\n",
      "breast_cancer  0.807692  0.631696  0.9375\n",
      "overall        0.807692  0.631696  0.9375\n"
     ]
    }
   ],
   "source": [
    "# adjusted model using Principal Component Analysis to reduce dimensionality over 1,000 iterations with scaled data\n",
    "acc,CIs = calculate_logReg(scaled_data, True, True, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e49ef",
   "metadata": {},
   "source": [
    "When comparing all these model, it shows that using scaled data improves the model. This was expected of a linear model. PCA did not improve but rather reduce model performance. This means that still a model with way many features than samples is used and other ways need to be found to reduce dimensionality. PCA reduces dimensionality unaware of the sample's class abels and is therefore considered an unsupervised approach. This makes PCA a sub-optimal approach for the classification problem of this thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c3cf21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb6bc160",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5dfd205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5185185185185185\n",
      "               median  0.025  0.975\n",
      "breast_cancer    0.55   0.55   0.55\n",
      "overall          0.55   0.55   0.55\n"
     ]
    }
   ],
   "source": [
    "# Grid search without PCA, 1 iteration\n",
    "acc,CIs = hyperparameter_optimization_logReg(scaled_data, False, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff7d4990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.747253  0.538799  0.916667\n",
      "overall        0.747253  0.538799  0.916667\n"
     ]
    }
   ],
   "source": [
    "# Grid search without PCA, 1000 iterations\n",
    "acc,CIs = hyperparameter_optimization_logReg(scaled_data, False, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e34c66bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5925925925925926\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.666667  0.666667  0.666667\n",
      "overall        0.666667  0.666667  0.666667\n"
     ]
    }
   ],
   "source": [
    "# Grid search with PCA, 1 iteration\n",
    "acc,CIs = hyperparameter_optimization_logReg(scaled_data, True, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b94fff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7037037037037037\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.817914  0.642045  0.944444\n",
      "overall        0.817914  0.642045  0.944444\n"
     ]
    }
   ],
   "source": [
    "# Grid search with PCA, 1000 iterations\n",
    "acc,CIs = hyperparameter_optimization_logReg(scaled_data, True, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4abd8",
   "metadata": {},
   "source": [
    "Hyperparameter optimization is highly variable between different runs and gives worse results compared to the default model, which should not happen. If the default parameter give a better perfromance these should be used in HPO. (HPO optimizes for accuracy and therefore this should at least be the same.) This indicates that the optimization does not work. In a dataset tht suffers from the curse of dimensionality determining the optimal value for each parameter is challenging. In this scenario it might be better to set the parameter manually according to the requirement of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ea476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
