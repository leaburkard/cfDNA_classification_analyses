{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a88186",
   "metadata": {},
   "source": [
    "# About the notebook\n",
    "This script computes gradient boosting models based on the features generated as part of the thesis. Different adjustments of the models are tested (e.g. scaled data, Principal Component Analysis for dimensionality reduction, adjusting the hyperparameter, hyperparameter optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c773c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve,auc,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b48827",
   "metadata": {},
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e51b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "cancer_type = \"breast_cancer\"\n",
    "GC = \"corrected\"\n",
    "score = \"MIDPOINT\"\n",
    "amplitude = \"FFT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86925f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breast cancer features\n",
    "file = \"/data/gpfs-1/groups/ag_kircher/cfDNA-analysis/lea/cfDNA_classification_analyses/features/DELFI_\"+cancer_type+\"_\"+GC+\"_\"+score+\"_\"+amplitude+\"_features.csv\"\n",
    "c_features = pd.read_csv(file, sep=\"\\t\", index_col=0)\n",
    "\n",
    "file = \"/data/gpfs-1/groups/ag_kircher/cfDNA-analysis/lea/cfDNA_classification_analyses/features/DELFI_\"+cancer_type+\"_metadata.tsv\"\n",
    "c_meta = pd.read_csv(file, sep='\\t', index_col='sample_name')\n",
    "\n",
    "c_features = c_features.reset_index(drop=False)\n",
    "c_features[['sample','p','score']] = c_features['index'].str.split('_',2, expand=True)\n",
    "c_features = c_features.set_index('sample')\n",
    "cancer = pd.concat([c_features, c_meta], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a098fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# healthy features\n",
    "file = \"/data/gpfs-1/groups/ag_kircher/cfDNA-analysis/lea/cfDNA_classification_analyses/features/DELFI_healthy_\"+GC+\"_\"+score+\"_\"+amplitude+\"_features.csv\"\n",
    "h_features = pd.read_csv(file, sep=\"\\t\", index_col=0)\n",
    "\n",
    "file = \"/data/gpfs-1/groups/ag_kircher/cfDNA-analysis/lea/cfDNA_classification_analyses/features/DELFI_healthy_metadata.tsv\"\n",
    "h_meta = pd.read_csv(file, sep='\\t', index_col='sample_name')\n",
    "\n",
    "h_features = h_features.reset_index(drop=False)\n",
    "h_features[['sample','p','score']] = h_features['index'].str.split('_',2, expand=True)\n",
    "h_features = h_features.set_index('sample')\n",
    "healthy = pd.concat([h_features, h_meta], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a2c7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>central_coverage_NFKB2</th>\n",
       "      <th>mean_coverage_NFKB2</th>\n",
       "      <th>amplitude190_NFKB2</th>\n",
       "      <th>nucleosome_spacing_fft_NFKB2</th>\n",
       "      <th>central_coverage_TP73</th>\n",
       "      <th>mean_coverage_TP73</th>\n",
       "      <th>amplitude190_TP73</th>\n",
       "      <th>nucleosome_spacing_fft_TP73</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Age</th>\n",
       "      <th>Status</th>\n",
       "      <th>% GC</th>\n",
       "      <th>Length</th>\n",
       "      <th>Median</th>\n",
       "      <th>≥ 1X</th>\n",
       "      <th>≥ 5X</th>\n",
       "      <th>fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EGAF00002727253</th>\n",
       "      <td>EGAF00002727253_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921859</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>5.964870</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.993629</td>\n",
       "      <td>0.999585</td>\n",
       "      <td>15.140059</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>I</td>\n",
       "      <td>54.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>140 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.06429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727240</th>\n",
       "      <td>EGAF00002727240_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966934</td>\n",
       "      <td>1.000200</td>\n",
       "      <td>19.353707</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.033113</td>\n",
       "      <td>1.000039</td>\n",
       "      <td>9.433198</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>61.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>42%</td>\n",
       "      <td>143 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>3.0%</td>\n",
       "      <td>0.36440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727280</th>\n",
       "      <td>EGAF00002727280_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.161236</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>11.505221</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1.115174</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>17.278634</td>\n",
       "      <td>192.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>37.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>42%</td>\n",
       "      <td>134 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.09767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727290</th>\n",
       "      <td>EGAF00002727290_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.027811</td>\n",
       "      <td>0.999776</td>\n",
       "      <td>20.178665</td>\n",
       "      <td>192.0</td>\n",
       "      <td>1.038958</td>\n",
       "      <td>1.000246</td>\n",
       "      <td>3.898227</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>48.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>139 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>89.0%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>0.06922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727254</th>\n",
       "      <td>EGAF00002727254_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.118326</td>\n",
       "      <td>1.000246</td>\n",
       "      <td>10.611337</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1.166457</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>1.834101</td>\n",
       "      <td>213.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>47.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>134 bp</td>\n",
       "      <td>1.0X</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.11470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1523 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      index  phenotype  \\\n",
       "EGAF00002727253  EGAF00002727253_c_MIDPOINT        1.0   \n",
       "EGAF00002727240  EGAF00002727240_c_MIDPOINT        1.0   \n",
       "EGAF00002727280  EGAF00002727280_c_MIDPOINT        1.0   \n",
       "EGAF00002727290  EGAF00002727290_c_MIDPOINT        1.0   \n",
       "EGAF00002727254  EGAF00002727254_c_MIDPOINT        1.0   \n",
       "\n",
       "                 central_coverage_NFKB2  mean_coverage_NFKB2  \\\n",
       "EGAF00002727253                0.921859             0.999899   \n",
       "EGAF00002727240                0.966934             1.000200   \n",
       "EGAF00002727280                1.161236             0.999987   \n",
       "EGAF00002727290                1.027811             0.999776   \n",
       "EGAF00002727254                1.118326             1.000246   \n",
       "\n",
       "                 amplitude190_NFKB2  nucleosome_spacing_fft_NFKB2  \\\n",
       "EGAF00002727253            5.964870                         148.0   \n",
       "EGAF00002727240           19.353707                         192.0   \n",
       "EGAF00002727280           11.505221                         213.0   \n",
       "EGAF00002727290           20.178665                         192.0   \n",
       "EGAF00002727254           10.611337                         213.0   \n",
       "\n",
       "                 central_coverage_TP73  mean_coverage_TP73  amplitude190_TP73  \\\n",
       "EGAF00002727253               0.993629            0.999585          15.140059   \n",
       "EGAF00002727240               1.033113            1.000039           9.433198   \n",
       "EGAF00002727280               1.115174            0.999805          17.278634   \n",
       "EGAF00002727290               1.038958            1.000246           3.898227   \n",
       "EGAF00002727254               1.166457            0.999947           1.834101   \n",
       "\n",
       "                 nucleosome_spacing_fft_TP73  ...  Gender  Stage   Age  \\\n",
       "EGAF00002727253                        192.0  ...       F      I  54.0   \n",
       "EGAF00002727240                        240.0  ...       F     II  61.0   \n",
       "EGAF00002727280                        192.0  ...       F     II  37.0   \n",
       "EGAF00002727290                        160.0  ...       F     II  48.0   \n",
       "EGAF00002727254                        213.0  ...       F     II  47.0   \n",
       "\n",
       "                        Status  % GC  Length  Median   ≥ 1X  ≥ 5X  fraction  \n",
       "EGAF00002727253  breast_cancer   41%  140 bp    2.0X  88.0%  1.0%   0.06429  \n",
       "EGAF00002727240  breast_cancer   42%  143 bp    2.0X  88.0%  3.0%   0.36440  \n",
       "EGAF00002727280  breast_cancer   42%  134 bp    2.0X  86.0%  1.0%   0.09767  \n",
       "EGAF00002727290  breast_cancer   41%  139 bp    2.0X  89.0%  2.0%   0.06922  \n",
       "EGAF00002727254  breast_cancer   41%  134 bp    1.0X  86.0%  1.0%   0.11470  \n",
       "\n",
       "[5 rows x 1523 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat breast cancer and healthy\n",
    "data = pd.concat([cancer, healthy], axis=0) \n",
    "\n",
    "features = data.columns[(data.columns.str.startswith('central_cov')) | (data.columns.str.startswith('mean_cov')) | (data.columns.str.startswith('amplitude')) | (data.columns.str.startswith('nucleosome_spacing_fft'))]\n",
    "features_phenotype = data.columns[(data.columns.str.startswith('phenotype')) | (data.columns.str.startswith('central_cov')) | (data.columns.str.startswith('mean_cov')) | (data.columns.str.startswith('amplitude')) | (data.columns.str.startswith('nucleosome_spacing_fft'))]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76df83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into a training (75%) and testing set (25%)\n",
    "train,test = train_test_split(data, test_size = 0.25, random_state = 42)\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train.loc[:,\"phenotype\"]\n",
    "X_test = test[features]\n",
    "y_test = test.loc[:,\"phenotype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b47691b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>central_coverage_NFKB2</th>\n",
       "      <th>mean_coverage_NFKB2</th>\n",
       "      <th>amplitude190_NFKB2</th>\n",
       "      <th>nucleosome_spacing_fft_NFKB2</th>\n",
       "      <th>central_coverage_TP73</th>\n",
       "      <th>mean_coverage_TP73</th>\n",
       "      <th>amplitude190_TP73</th>\n",
       "      <th>nucleosome_spacing_fft_TP73</th>\n",
       "      <th>...</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Age</th>\n",
       "      <th>Status</th>\n",
       "      <th>% GC</th>\n",
       "      <th>Length</th>\n",
       "      <th>Median</th>\n",
       "      <th>≥ 1X</th>\n",
       "      <th>≥ 5X</th>\n",
       "      <th>fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EGAF00002727253</th>\n",
       "      <td>EGAF00002727253_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.587964</td>\n",
       "      <td>-0.402804</td>\n",
       "      <td>-1.431977</td>\n",
       "      <td>-2.181180</td>\n",
       "      <td>-1.235524</td>\n",
       "      <td>-2.211313</td>\n",
       "      <td>0.879156</td>\n",
       "      <td>-0.406840</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>I</td>\n",
       "      <td>54.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>140 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.06429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727240</th>\n",
       "      <td>EGAF00002727240_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.575681</td>\n",
       "      <td>1.081786</td>\n",
       "      <td>0.380465</td>\n",
       "      <td>-0.469377</td>\n",
       "      <td>-0.233665</td>\n",
       "      <td>0.148223</td>\n",
       "      <td>-0.184884</td>\n",
       "      <td>1.386579</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>61.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>42%</td>\n",
       "      <td>143 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>88.0%</td>\n",
       "      <td>3.0%</td>\n",
       "      <td>0.36440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727280</th>\n",
       "      <td>EGAF00002727280_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.787805</td>\n",
       "      <td>0.031149</td>\n",
       "      <td>-0.681981</td>\n",
       "      <td>0.347620</td>\n",
       "      <td>1.848499</td>\n",
       "      <td>-1.066968</td>\n",
       "      <td>1.277891</td>\n",
       "      <td>-0.406840</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>37.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>42%</td>\n",
       "      <td>134 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.09767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727290</th>\n",
       "      <td>EGAF00002727290_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791448</td>\n",
       "      <td>-1.014266</td>\n",
       "      <td>0.492140</td>\n",
       "      <td>-0.469377</td>\n",
       "      <td>-0.085350</td>\n",
       "      <td>1.227604</td>\n",
       "      <td>-1.216876</td>\n",
       "      <td>-1.602453</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>48.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>139 bp</td>\n",
       "      <td>2.0X</td>\n",
       "      <td>89.0%</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>0.06922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAF00002727254</th>\n",
       "      <td>EGAF00002727254_c_MIDPOINT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.824170</td>\n",
       "      <td>1.308605</td>\n",
       "      <td>-0.802986</td>\n",
       "      <td>0.347620</td>\n",
       "      <td>3.149750</td>\n",
       "      <td>-0.327229</td>\n",
       "      <td>-1.601730</td>\n",
       "      <td>0.377780</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>47.0</td>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>41%</td>\n",
       "      <td>134 bp</td>\n",
       "      <td>1.0X</td>\n",
       "      <td>86.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>0.11470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1523 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      index  phenotype  \\\n",
       "EGAF00002727253  EGAF00002727253_c_MIDPOINT        1.0   \n",
       "EGAF00002727240  EGAF00002727240_c_MIDPOINT        1.0   \n",
       "EGAF00002727280  EGAF00002727280_c_MIDPOINT        1.0   \n",
       "EGAF00002727290  EGAF00002727290_c_MIDPOINT        1.0   \n",
       "EGAF00002727254  EGAF00002727254_c_MIDPOINT        1.0   \n",
       "\n",
       "                 central_coverage_NFKB2  mean_coverage_NFKB2  \\\n",
       "EGAF00002727253               -1.587964            -0.402804   \n",
       "EGAF00002727240               -0.575681             1.081786   \n",
       "EGAF00002727280                3.787805             0.031149   \n",
       "EGAF00002727290                0.791448            -1.014266   \n",
       "EGAF00002727254                2.824170             1.308605   \n",
       "\n",
       "                 amplitude190_NFKB2  nucleosome_spacing_fft_NFKB2  \\\n",
       "EGAF00002727253           -1.431977                     -2.181180   \n",
       "EGAF00002727240            0.380465                     -0.469377   \n",
       "EGAF00002727280           -0.681981                      0.347620   \n",
       "EGAF00002727290            0.492140                     -0.469377   \n",
       "EGAF00002727254           -0.802986                      0.347620   \n",
       "\n",
       "                 central_coverage_TP73  mean_coverage_TP73  amplitude190_TP73  \\\n",
       "EGAF00002727253              -1.235524           -2.211313           0.879156   \n",
       "EGAF00002727240              -0.233665            0.148223          -0.184884   \n",
       "EGAF00002727280               1.848499           -1.066968           1.277891   \n",
       "EGAF00002727290              -0.085350            1.227604          -1.216876   \n",
       "EGAF00002727254               3.149750           -0.327229          -1.601730   \n",
       "\n",
       "                 nucleosome_spacing_fft_TP73  ...  Gender  Stage   Age  \\\n",
       "EGAF00002727253                    -0.406840  ...       F      I  54.0   \n",
       "EGAF00002727240                     1.386579  ...       F     II  61.0   \n",
       "EGAF00002727280                    -0.406840  ...       F     II  37.0   \n",
       "EGAF00002727290                    -1.602453  ...       F     II  48.0   \n",
       "EGAF00002727254                     0.377780  ...       F     II  47.0   \n",
       "\n",
       "                        Status  % GC  Length  Median   ≥ 1X  ≥ 5X  fraction  \n",
       "EGAF00002727253  breast_cancer   41%  140 bp    2.0X  88.0%  1.0%   0.06429  \n",
       "EGAF00002727240  breast_cancer   42%  143 bp    2.0X  88.0%  3.0%   0.36440  \n",
       "EGAF00002727280  breast_cancer   42%  134 bp    2.0X  86.0%  1.0%   0.09767  \n",
       "EGAF00002727290  breast_cancer   41%  139 bp    2.0X  89.0%  2.0%   0.06922  \n",
       "EGAF00002727254  breast_cancer   41%  134 bp    1.0X  86.0%  1.0%   0.11470  \n",
       "\n",
       "[5 rows x 1523 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale data\n",
    "scaled_data = pd.concat([cancer, healthy], axis=0) \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(scaled_data[features])\n",
    "scaled_data[features] = scaler.transform(scaled_data[features])\n",
    "scaled_data[features].mean()\n",
    "\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86b52fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split scaled data into a training (75%) and testing set (25%)\n",
    "train_scaled,test_scaled = train_test_split(scaled_data, test_size = 0.25, random_state = 42)\n",
    "\n",
    "X_train_scaled = train_scaled[features]\n",
    "y_train_scaled = train_scaled.loc[:,\"phenotype\"]\n",
    "X_test_scaled = test_scaled[features]\n",
    "y_test_scaled = test_scaled.loc[:,\"phenotype\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09768c00",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce34d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AUC_griffin(prob,data):\n",
    "    #get AUC and accuracy for each bootstrap\n",
    "    probabilities = pd.DataFrame(index=data.index)\n",
    "    probabilities[0] = pd.Series(prob[:,1], index = X_test.index)\n",
    "    probabilities = probabilities.merge(data[['phenotype']], left_index=True, right_index=True)\n",
    "\n",
    "    AUCs = pd.DataFrame()\n",
    "\n",
    "    probabilities = probabilities.merge(data[['fraction','Status','Stage','Median']], left_index=True, right_index=True)\n",
    "    \n",
    "    for i in range(1):\n",
    "        current_dict = {}\n",
    "        current = probabilities[~(probabilities[i].isnull())][['phenotype','fraction','Status','Stage','Median',i]].copy()\n",
    "\n",
    "        #overall accuracy and AUC\n",
    "        group = 'overall'\n",
    "        fpr,tpr,_ = roc_curve(current['phenotype'],current[i])\n",
    "        AUC = auc(fpr,tpr)\n",
    "        current_dict[group] = AUC\n",
    "        mean_fpr = fpr\n",
    "        mean_tpr = tpr\n",
    "        del(AUC,group,fpr,tpr)\n",
    "\n",
    "        #separate out the healthy samples to be used in every AUC\n",
    "        healthy_df = current[current['phenotype']==0]\n",
    "        cancer_df = current[current['phenotype']==1]\n",
    "        del(current)\n",
    "        \n",
    "        for group,df in cancer_df.groupby('Status'):\n",
    "            if group == 'Duodenal_Cancer':\n",
    "                continue\n",
    "\n",
    "            df2 = df.append(healthy_df, ignore_index=True)\n",
    "            fpr,tpr,_ = roc_curve(df2['phenotype'],df2[i])\n",
    "            AUC = auc(fpr,tpr)\n",
    "            current_dict[group] = AUC\n",
    "            del(AUC,group,fpr,tpr)\n",
    "        \n",
    "        for group,df in cancer_df.groupby('Median'):\n",
    "            df2 = df.append(healthy_df, ignore_index=True)\n",
    "            fpr,tpr,_ = roc_curve(df2['phenotype'],df2[i])\n",
    "            AUC = auc(fpr,tpr)\n",
    "            current_dict[group] = AUC\n",
    "            del(AUC,group,fpr,tpr)\n",
    "        \n",
    "        AUCs = AUCs.append(pd.Series(current_dict), ignore_index=True)\n",
    "        \n",
    "    CIs = pd.DataFrame([AUCs.median(), AUCs.quantile(.025), AUCs.quantile(.975)]).T\n",
    "    CIs = CIs.rename(columns = {'Unnamed 0':'median'})    \n",
    "    return(AUCs,CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e83227b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_data(prob,data):\n",
    "    #get AUC and accuracy for each bootstrap\n",
    "    probabilities = pd.DataFrame(index=data.index)\n",
    "    probabilities[0] = pd.Series(prob[:,1], index = X_test.index)\n",
    "    probabilities = probabilities.merge(data[['phenotype']], left_index=True, right_index=True)\n",
    "    probabilities = probabilities.merge(data[['fraction','Status','Stage','Median']], left_index=True, right_index=True)\n",
    "    \n",
    "    AUCs = pd.DataFrame()\n",
    "    current_dict = {}\n",
    "    current = probabilities[~(probabilities[0].isnull())][['phenotype','fraction','Status','Stage','Median',0]].copy()\n",
    "\n",
    "    #overall accuracy and AUC\n",
    "    group = 'overall'\n",
    "    fpr,tpr,_ = roc_curve(current['phenotype'],current[0])\n",
    "    AUC = auc(fpr,tpr)\n",
    "    current_dict[group] = AUC\n",
    "\n",
    "    AUCs = AUCs.append(pd.Series(current_dict), ignore_index=True)\n",
    "        \n",
    "    CIs = pd.DataFrame([AUCs.median(), AUCs.quantile(.025), AUCs.quantile(.975)]).T\n",
    "    CIs = CIs.rename(columns = {'Unnamed 0':'median'})    \n",
    "    return(fpr,tpr,AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67100de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_GBC(data, PCA_flag, adjustment_flag, iterations):\n",
    "    fraction_variance = .8\n",
    "    probabilities = pd.DataFrame(index=data.index)\n",
    "    coefs = pd.DataFrame(index=features)\n",
    "    train_indexes = []\n",
    "\n",
    "    # Loop for each iteration\n",
    "    for i in range(iterations):\n",
    "\n",
    "        train_internal,test_internal = train_test_split(data, test_size = 0.25, random_state = i+100) #, random_state = 42\n",
    "        X_train_internal = train_internal[features]\n",
    "        y_train_internal = train_internal.loc[:,\"phenotype\"]\n",
    "        X_test_internal = test_internal[features]\n",
    "        y_test_internal = test_internal.loc[:,\"phenotype\"]\n",
    "        \n",
    "        if PCA_flag == True:\n",
    "            #perform PCA on the training set\n",
    "            n_components = min(len(features), len(X_train_internal))\n",
    "            pca = PCA(n_components=n_components, svd_solver='randomized', random_state = 100)\n",
    "            PCs = pca.fit_transform(X_train_internal[features])\n",
    "            principal_components = pd.DataFrame(data = PCs, columns = ['PC_'+str(m) for m in np.arange(n_components)], index = X_train_internal.index)\n",
    "\n",
    "            #find the principle components that make up 80% of the varience\n",
    "            for j in range(len(pca.explained_variance_ratio_)):\n",
    "                current_sum = pca.explained_variance_ratio_[:j].sum()\n",
    "                if current_sum>=fraction_variance:\n",
    "                    break\n",
    "            pca_features = ['PC_'+str(m) for m in np.arange(0,j)]\n",
    "\n",
    "            #apply to the test data\n",
    "            test_PCs = pca.transform(X_test_internal[features])\n",
    "            test_principal_components = pd.DataFrame(data = test_PCs , columns = ['PC_'+str(m) for m in np.arange(n_components)], index = X_test_internal.index)\n",
    "\n",
    "            X_train_internal = principal_components[pca_features]\n",
    "            X_test_internal = test_principal_components[pca_features]\n",
    "        \n",
    "        if adjustment_flag == True:\n",
    "            model = GradientBoostingClassifier(n_estimators=300, min_samples_leaf=3)\n",
    "        else:\n",
    "            model = GradientBoostingClassifier()\n",
    "\n",
    "        #train a new model \n",
    "        model.fit(X_train_internal, y_train_internal)\n",
    "\n",
    "        #predict the test data\n",
    "        pred = model.predict(X_test_internal)\n",
    "        prob = model.predict_proba(X_test_internal)\n",
    "\n",
    "        #save results\n",
    "        probabilities[i] = pd.Series(prob[:,1], index = X_test_internal.index)\n",
    "        acc = accuracy_score(y_test_internal, pred)\n",
    "        train_indexes.append(list(X_train_internal.index))\n",
    "\n",
    "        if i%20==0:\n",
    "            #prevent dfs from becoming too fragmented\n",
    "            probabilities = probabilities.copy()\n",
    "            coefs = coefs.copy()\n",
    "\n",
    "    probabilities = probabilities.merge(data[['phenotype']], left_index=True, right_index=True)    \n",
    "    AUCs = pd.DataFrame()\n",
    "    probabilities = probabilities.merge(data[['fraction','Status','Stage']], left_index=True, right_index=True)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        current_dict = {}\n",
    "        current = probabilities[~(probabilities[i].isnull())][['phenotype','fraction','Status','Stage',i]].copy()\n",
    "\n",
    "        #overall accuracy and AUC\n",
    "        group = 'overall'\n",
    "        fpr,tpr,_ = roc_curve(current['phenotype'],current[i])\n",
    "        AUC = auc(fpr,tpr)\n",
    "        current_dict[group] = AUC\n",
    "        del(AUC,group,fpr,tpr)\n",
    "\n",
    "        #separate out the healthy samples to be used in every AUC\n",
    "        healthy_df = current[current['phenotype']==0]\n",
    "        cancer_df = current[current['phenotype']==1]\n",
    "        del(current)\n",
    "\n",
    "        for group,df in cancer_df.groupby('Status'):\n",
    "            if group == 'Duodenal_Cancer':\n",
    "                continue\n",
    "\n",
    "            df2 = df.append(healthy_df, ignore_index=True)\n",
    "            fpr,tpr,_ = roc_curve(df2['phenotype'],df2[i])\n",
    "            AUC = auc(fpr,tpr)\n",
    "            current_dict[group] = AUC\n",
    "            del(AUC,group,fpr,tpr)\n",
    "\n",
    "        AUCs = AUCs.append(pd.Series(current_dict), ignore_index=True)\n",
    "\n",
    "    CIs = pd.DataFrame([AUCs.median(), AUCs.quantile(.025), AUCs.quantile(.975)]).T\n",
    "    CIs = CIs.rename(columns = {'Unnamed 0':'median'}) \n",
    "    return(acc,CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18eb5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization_GBC(data, PCA_flag, HPO_type, iterations):\n",
    "    fraction_variance = .8\n",
    "    probabilities = pd.DataFrame(index=data.index)\n",
    "    c_vals = []\n",
    "    coefs = pd.DataFrame(index=features)\n",
    "    train_indexes = []\n",
    "\n",
    "    # Loop for each iteration\n",
    "    for i in range(iterations):\n",
    "\n",
    "        train_internal,test_internal = train_test_split(data, test_size = 0.25, random_state = i+100) #, random_state = 42\n",
    "        X_train_internal = train_internal[features]\n",
    "        y_train_internal = train_internal.loc[:,\"phenotype\"]\n",
    "        X_test_internal = test_internal[features]\n",
    "        y_test_internal = test_internal.loc[:,\"phenotype\"]\n",
    "        \n",
    "        if PCA_flag == True:\n",
    "            #perform PCA on the training set\n",
    "            n_components = min(len(features), len(X_train_internal))\n",
    "            pca = PCA(n_components=n_components, svd_solver='randomized', random_state = 100)\n",
    "            PCs = pca.fit_transform(X_train_internal[features])\n",
    "            principal_components = pd.DataFrame(data = PCs, columns = ['PC_'+str(m) for m in np.arange(n_components)], index = X_train_internal.index)\n",
    "\n",
    "            #find the principle components that make up 80% of the varience\n",
    "            for j in range(len(pca.explained_variance_ratio_)):\n",
    "                current_sum = pca.explained_variance_ratio_[:j].sum()\n",
    "                if current_sum>=fraction_variance:\n",
    "                    break\n",
    "            pca_features = ['PC_'+str(m) for m in np.arange(0,j)]\n",
    "\n",
    "            #apply to the test data\n",
    "            test_PCs = pca.transform(X_test_internal[features])\n",
    "            test_principal_components = pd.DataFrame(data = test_PCs , columns = ['PC_'+str(m) for m in np.arange(n_components)], index = X_test_internal.index)\n",
    "\n",
    "            X_train_internal = principal_components[pca_features]\n",
    "            X_test_internal = test_principal_components[pca_features]\n",
    "        \n",
    "        if HPO_type == \"random\" and i == 0:\n",
    "            n_estimators = range(100,501,50) \n",
    "            max_features = ['sqrt','log2',None] \n",
    "            min_samples_leaf = range(2,6)\n",
    "            max_depth = range(3,16)\n",
    "            min_samples_split = range(2,5)\n",
    "\n",
    "            hyperparameters = {'n_estimators': n_estimators,\n",
    "                            'max_features': max_features,\n",
    "                            'min_samples_leaf': min_samples_leaf,\n",
    "                            'max_depth': max_depth,\n",
    "                            'min_samples_split': min_samples_split}\n",
    "\n",
    "            cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = i+100) \n",
    "\n",
    "            model = GradientBoostingClassifier()\n",
    "            search = RandomizedSearchCV(estimator = model, param_distributions = hyperparameters, n_iter = 500,  cv = cv, verbose=3, n_jobs = -1, return_train_score=True)        \n",
    "            search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "            best_n_estimators = search.best_params_['n_estimators']\n",
    "            best_max_features = search.best_params_['max_features']\n",
    "            best_min_samples_leaf = search.best_params_['min_samples_leaf']\n",
    "            best_max_depth = search.best_params_['max_depth']\n",
    "            best_min_samples_split = search.best_params_['min_samples_split']\n",
    "        \n",
    "        if HPO_type == \"grid\" and i == 0:\n",
    "            n_estimators = range(100,501,50) \n",
    "            max_features = ['sqrt','log2',None] \n",
    "            min_samples_leaf = range(2,6)\n",
    "            max_depth = range(3,16)\n",
    "            min_samples_split = range(2,5)\n",
    "\n",
    "            hyperparameters = {'n_estimators': n_estimators,\n",
    "                            'max_features': max_features,\n",
    "                            'min_samples_leaf': min_samples_leaf,\n",
    "                            'max_depth': max_depth,\n",
    "                            'min_samples_split': min_samples_split}\n",
    "\n",
    "            cv = StratifiedKFold(n_splits=10, shuffle=True, random_state = i+100) \n",
    "            model = GradientBoostingClassifier()\n",
    "            search = GridSearchCV(estimator = model, param_grid = hyperparameters,  cv = cv, verbose=2, n_jobs = -1)\n",
    "            search.fit(X_train_internal, y_train_internal)\n",
    "\n",
    "            best_n_estimators = search.best_params_['n_estimators']\n",
    "            best_max_features = search.best_params_['max_features']\n",
    "            best_min_samples_leaf = search.best_params_['min_samples_leaf']\n",
    "            best_max_depth = search.best_params_['max_depth']\n",
    "            best_min_samples_split = search.best_params_['min_samples_split']\n",
    "        \n",
    "        model = GradientBoostingClassifier(n_estimators=best_n_estimators, max_features=best_max_features, \n",
    "                                           min_samples_leaf=best_min_samples_leaf, \n",
    "                                           max_depth=best_max_depth, min_samples_split=best_min_samples_split)\n",
    "        \n",
    "        #train a new model \n",
    "        model.fit(X_train_internal, y_train_internal)\n",
    "\n",
    "        #predict the test data\n",
    "        pred = model.predict(X_test_internal)\n",
    "        prob = model.predict_proba(X_test_internal)\n",
    "\n",
    "        #save results\n",
    "        probabilities[i] = pd.Series(prob[:,1], index = X_test_internal.index)\n",
    "        acc = accuracy_score(y_test_internal, pred)\n",
    "        train_indexes.append(list(X_train_internal.index))\n",
    "\n",
    "        if i%20==0:\n",
    "            #prevent dfs from becoming too fragmented\n",
    "            probabilities = probabilities.copy()\n",
    "            coefs = coefs.copy()   \n",
    "            #sys.stdout.flush()\n",
    "\n",
    "    probabilities = probabilities.merge(data[['phenotype']], left_index=True, right_index=True)\n",
    "    AUCs = pd.DataFrame()\n",
    "    probabilities = probabilities.merge(data[['fraction','Status','Stage']], left_index=True, right_index=True)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        current_dict = {}\n",
    "        current = probabilities[~(probabilities[i].isnull())][['phenotype','fraction','Status','Stage',i]].copy()\n",
    "\n",
    "        #overall accuracy and AUC\n",
    "        group = 'overall'\n",
    "        fpr,tpr,_ = roc_curve(current['phenotype'],current[i])\n",
    "        AUC = auc(fpr,tpr)\n",
    "        current_dict[group] = AUC\n",
    "        del(AUC,group,fpr,tpr)\n",
    "\n",
    "        #separate out the healthy samples to be used in every AUC\n",
    "        healthy_df = current[current['phenotype']==0]\n",
    "        cancer_df = current[current['phenotype']==1]\n",
    "        del(current)\n",
    "\n",
    "        for group,df in cancer_df.groupby('Status'):\n",
    "            if group == 'Duodenal_Cancer':\n",
    "                continue\n",
    "\n",
    "            df2 = df.append(healthy_df, ignore_index=True)\n",
    "            fpr,tpr,_ = roc_curve(df2['phenotype'],df2[i])\n",
    "            AUC = auc(fpr,tpr)\n",
    "            current_dict[group] = AUC\n",
    "            del(AUC,group,fpr,tpr)\n",
    "\n",
    "        AUCs = AUCs.append(pd.Series(current_dict), ignore_index=True)\n",
    "\n",
    "    CIs = pd.DataFrame([AUCs.median(), AUCs.quantile(.025), AUCs.quantile(.975)]).T\n",
    "    CIs = CIs.rename(columns = {'Unnamed 0':'median'}) \n",
    "    return(acc,CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece7023",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier\n",
    "First try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "660b16fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7037037037037037"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "gbc_all_default = GradientBoostingClassifier(random_state=42)\n",
    "gbc_all_default.fit(X_train, y_train)\n",
    "\n",
    "# test model\n",
    "\n",
    "predict_train = gbc_all_default.predict(X_train)\n",
    "predict_test = gbc_all_default.predict(X_test)\n",
    "probability_test = gbc_all_default.predict_proba(X_test)\n",
    "\n",
    "accuracy_score(y_test, predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a48991b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median</th>\n",
       "      <th>0.025</th>\n",
       "      <th>0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0X</th>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0X</th>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.684615</td>\n",
       "      <td>0.684615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0X</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.747253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.747253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 median     0.025     0.975\n",
       "1.0X           0.961538  0.961538  0.961538\n",
       "2.0X           0.684615  0.684615  0.684615\n",
       "3.0X           0.846154  0.846154  0.846154\n",
       "breast_cancer  0.747253  0.747253  0.747253\n",
       "overall        0.747253  0.747253  0.747253"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCs,CIs = get_AUC_griffin(probability_test,data)\n",
    "CIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3f17a",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier\n",
    "First train a gradient boosting classifier with all features on default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ea91e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407407407407407\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.816667  0.816667  0.816667\n",
      "overall        0.816667  0.816667  0.816667\n"
     ]
    }
   ],
   "source": [
    "# default model \n",
    "acc,CIs = calculate_GBC(data, False, False, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8102c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "                 median    0.025     0.975\n",
      "breast_cancer  0.772727  0.53974  0.956149\n",
      "overall        0.772727  0.53974  0.956149\n"
     ]
    }
   ],
   "source": [
    "# default model over 1,000 iterations\n",
    "acc,CIs = calculate_GBC(data, False, False, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faa0df4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7037037037037037\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.766667  0.766667  0.766667\n",
      "overall        0.766667  0.766667  0.766667\n"
     ]
    }
   ],
   "source": [
    "# default model using Principal Component Analysis to reduce dimensionality\n",
    "acc,CIs = calculate_GBC(data, True, False, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d1bf9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48148148148148145\n",
      "                 median  0.025     0.975\n",
      "breast_cancer  0.615385    0.4  0.805633\n",
      "overall        0.615385    0.4  0.805633\n"
     ]
    }
   ],
   "source": [
    "# default model using Principal Component Analysis to reduce dimensionality over 1,000 iterations\n",
    "acc,CIs = calculate_GBC(data, True, False, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244a529",
   "metadata": {},
   "source": [
    "Rerun the models using scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa99894b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.866667  0.866667  0.866667\n",
      "overall        0.866667  0.866667  0.866667\n"
     ]
    }
   ],
   "source": [
    "# default model with scaled data\n",
    "acc,CIs = calculate_GBC(scaled_data, False, False, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04254230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.767782  0.534091  0.961111\n",
      "overall        0.767782  0.534091  0.961111\n"
     ]
    }
   ],
   "source": [
    "# default model over 1,000 iterations with scaled data\n",
    "acc,CIs = calculate_GBC(scaled_data, False, False, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a0f8faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555555555555556\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.666667  0.666667  0.666667\n",
      "overall        0.666667  0.666667  0.666667\n"
     ]
    }
   ],
   "source": [
    "# default model using Principal Component Analysis to reduce dimensionality with scaled data\n",
    "acc,CIs = calculate_GBC(scaled_data, True, False, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2640a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "                 median  0.025     0.975\n",
      "breast_cancer  0.782843    0.6  0.917584\n",
      "overall        0.782843    0.6  0.917584\n"
     ]
    }
   ],
   "source": [
    "# default model using Principal Component Analysis to reduce dimensionality over 1,000 iterations with scaled data\n",
    "acc,CIs = calculate_GBC(scaled_data, True, False, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29425296",
   "metadata": {},
   "source": [
    "Now use a gradient boosting model with adjusted hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4d7c92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148148148148148\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.872222  0.872222  0.872222\n",
      "overall        0.872222  0.872222  0.872222\n"
     ]
    }
   ],
   "source": [
    "# adjusted model \n",
    "acc,CIs = calculate_GBC(data, False, True, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82643909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.851648  0.648254  0.972527\n",
      "overall        0.851648  0.648254  0.972527\n"
     ]
    }
   ],
   "source": [
    "# adjusted model over 1,000 iterations\n",
    "acc,CIs = calculate_GBC(data, False, True, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "819be30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7407407407407407\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.777778  0.777778  0.777778\n",
      "overall        0.777778  0.777778  0.777778\n"
     ]
    }
   ],
   "source": [
    "# adjusted model using Principal Component Analysis to reduce dimensionality\n",
    "acc,CIs = calculate_GBC(data, True, True, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "860f7939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5185185185185185\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.611111  0.395575  0.805564\n",
      "overall        0.611111  0.395575  0.805564\n"
     ]
    }
   ],
   "source": [
    "# adjusted model using Principal Component Analysis to reduce dimensionality over 1,000 iterations\n",
    "acc,CIs = calculate_GBC(data, True, True, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef702c2",
   "metadata": {},
   "source": [
    "And use the adjusted model with scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c09256bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5925925925925926\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.788889  0.788889  0.788889\n",
      "overall        0.788889  0.788889  0.788889\n"
     ]
    }
   ],
   "source": [
    "# adjusted model with scaled data\n",
    "acc,CIs = calculate_GBC(scaled_data, False, True, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "755afe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296296296296297\n",
      "                 median     0.025    0.975\n",
      "breast_cancer  0.851648  0.638826  0.97223\n",
      "overall        0.851648  0.638826  0.97223\n"
     ]
    }
   ],
   "source": [
    "# adjusted model over 1,000 iterations with scaled data\n",
    "acc,CIs = calculate_GBC(scaled_data, False, True, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7c427f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555555555555556\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.644444  0.644444  0.644444\n",
      "overall        0.644444  0.644444  0.644444\n"
     ]
    }
   ],
   "source": [
    "# adjusted model using Principal Component Analysis to reduce dimensionality with scaled data\n",
    "acc,CIs = calculate_GBC(scaled_data, True, True, 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7f624bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "                 median     0.025    0.975\n",
      "breast_cancer  0.778409  0.596537  0.91482\n",
      "overall        0.778409  0.596537  0.91482\n"
     ]
    }
   ],
   "source": [
    "# adjusted model using Principal Component Analysis to reduce dimensionality over 1,000 iterations with scaled data\n",
    "acc,CIs = calculate_GBC(scaled_data, True, True, 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49735f7",
   "metadata": {},
   "source": [
    "When comparing all these model, it shows that using scaled data does not improve the model. This was expected of a tree-based model. However, the scaled data was still used as it did not reduce model performance and is still needed for PCA, which is a linear approach to reduce dimensionality. It also makes all three models more comparable. \n",
    "PCA did not improve but rather reduce model performance. This means that still a model with way many features than samples is used and other ways need to be found to reduce dimensionality. PCA reduces dimensionality unaware of the sample's class abels and is therefore considered an unsupervised approach. This makes PCA a sub-optimal approach for the classification problem of this thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e32ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "573d9f39",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c69ff569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n",
      "0.7037037037037037\n",
      "               median  0.025  0.975\n",
      "breast_cancer     0.8    0.8    0.8\n",
      "overall           0.8    0.8    0.8\n"
     ]
    }
   ],
   "source": [
    "# Random search without PCA, 1 iteration\n",
    "acc,CIs = hyperparameter_optimization_GBC(data, False, \"random\", 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cf47157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n",
      "0.7407407407407407\n",
      "                 median     0.025     0.975\n",
      "breast_cancer  0.894444  0.752679  0.983516\n",
      "overall        0.894444  0.752679  0.983516\n"
     ]
    }
   ],
   "source": [
    "# Random search without PCA, 1000 iterations\n",
    "acc,CIs = hyperparameter_optimization_GBC(data, False, \"random\", 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fe0c1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n",
      "0.5555555555555556\n",
      "                 median  0.025     0.975\n",
      "breast_cancer  0.607955    0.4  0.817761\n",
      "overall        0.607955    0.4  0.817761\n"
     ]
    }
   ],
   "source": [
    "# Random search with PCA, 1000 iterations\n",
    "acc,CIs = hyperparameter_optimization_GBC(data, True, \"random\", 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d3f6104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4212 candidates, totalling 42120 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a72aee928fcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Grid search without PCA, 1 iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCIs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameter_optimization_GBC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"grid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCIs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-28959fc08ab2>\u001b[0m in \u001b[0;36mhyperparameter_optimization_GBC\u001b[0;34m(data, PCA_flag, HPO_type, iterations)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_internal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_internal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mbest_n_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/users/lburkar_m/work/miniconda/envs/jupyter/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid search without PCA, 1 iteration\n",
    "acc,CIs = hyperparameter_optimization_GBC(data, False, \"grid\", 1)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90fa608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search without PCA, 1000 iterations\n",
    "acc,CIs = hyperparameter_optimization_GBC(data, False, \"grid\", 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search with PCA, 1000 iterations\n",
    "acc,CIs = hyperparameter_optimization_GBC(data, True, \"grid\", 1000)\n",
    "print(acc)\n",
    "print(CIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc495ba3",
   "metadata": {},
   "source": [
    "Hyperparameter optimization is highly variable between different runs and gives worse results compared to the default model, which should not happen. If the default parameter give a better perfromance these should be used in HPO. (HPO optimizes for accuracy and therefore this should at least be the same.) This indicates that the optimization does not work. In a dataset tht suffers from the curse of dimensionality determining the optimal value for each parameter is challenging. In this scenario it might be better to set the parameter manually according to the requirement of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df118653",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GBC with selected features on default parameters\n",
    "# use the gbc_all_default to select feature importance\n",
    "\n",
    "feature_imp_gbc = pd.DataFrame(data=gbc_all_default.feature_importances_, columns=[\"importance\"], index=features).sort_values(by=\"importance\", ascending=False)\n",
    "n_features = 20\n",
    "feature_imp_gbc.head(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac955ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dataframe\n",
    "reduced_gbc = feature_imp_gbc.sort_values(by=\"importance\", ascending=False).head(n_features).index\n",
    "features_reduced_gbc = data.loc[:,reduced_gbc]\n",
    "features_reduced_gbc[\"phenotype\"] = data[\"phenotype\"]\n",
    "features_reduced_gbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86104253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new model on the reduced features\n",
    "train_reduced_default,test_reduced_default = train_test_split(features_reduced_gbc, test_size = 0.25, random_state = 42)\n",
    "\n",
    "# train reduced model\n",
    "X_train_reduced_default = train_reduced_default.drop([\"phenotype\"], axis = 1)\n",
    "y_train_reduced_default = train_reduced_default.loc[:,\"phenotype\"]\n",
    "X_test_reduced_default = test_reduced_default.drop([\"phenotype\"], axis = 1)\n",
    "y_test_reduced_default = test_reduced_default.loc[:,\"phenotype\"]\n",
    "\n",
    "gbc_reduced_default = GradientBoostingClassifier(random_state=42)\n",
    "gbc_reduced_default.fit(X_train_reduced_default, y_train_reduced_default)\n",
    "\n",
    "# test model\n",
    "predict_train = gbc_reduced_default.predict(X_train_reduced_default)\n",
    "predict_test = gbc_reduced_default.predict(X_test_reduced_default)\n",
    "probability_test = gbc_reduced_default.predict_proba(X_test_reduced_default)\n",
    "\n",
    "accuracy_score(y_test_reduced_default, predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1161c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUCs,CIs = get_AUC_griffin(probability_test,data)\n",
    "CIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79720b9b",
   "metadata": {},
   "source": [
    "Training a model only with the 20 features of highest feature importance does not improve model perfomance. It seems that the model with all features already ony includes features of high importance and therefore this approach is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b386a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
